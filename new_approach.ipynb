{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "328f526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "import scipy.signal\n",
    "import neurokit2 as nk\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b967a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import keras.metrics\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc92dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(\"./Data_preprocessed/\"))\n",
    "#path, dirs, files = next(os.walk(\"./Data2/\"))\n",
    "nod=len(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b81fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def df_resample(df1, num=1):\n",
    "    df2 = pd.DataFrame()\n",
    "    for key, value in df1.iteritems(): \n",
    "        temp = value.to_numpy()/value.abs().max() # normalize\n",
    "        resampled = resize(temp, (num,1), mode='edge')*value.abs().max() # de-normalize\n",
    "        df2[key] = resampled.flatten().round(2)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75ef790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "./Data_preprocessed/Left_Crossing\n",
      "100\n",
      "1\n",
      "./Data_preprocessed/Left_Roundabout\n",
      "100\n",
      "2\n",
      "./Data_preprocessed/Parking_Diagonal_Left\n",
      "100\n",
      "3\n",
      "./Data_preprocessed/Parking_Diagonal_Right\n",
      "100\n",
      "4\n",
      "./Data_preprocessed/Parking_Parallel_Left\n",
      "100\n",
      "5\n",
      "./Data_preprocessed/Parking_Parallel_Right\n",
      "100\n",
      "6\n",
      "./Data_preprocessed/Parking_Perpendicular_Left\n",
      "100\n",
      "7\n",
      "./Data_preprocessed/Parking_Perpendicular_Right\n",
      "100\n",
      "8\n",
      "./Data_preprocessed/Right_Crossing\n",
      "100\n",
      "9\n",
      "./Data_preprocessed/Right_Roundabout\n",
      "100\n",
      "10\n",
      "./Data_preprocessed/Straight_Crossing\n",
      "100\n",
      "11\n",
      "./Data_preprocessed/Straight_Roundabout\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "dataframes_list_test = list()\n",
    "labels_list_test = list()\n",
    "dataframes_list_train = list()\n",
    "labels_list_train = list()\n",
    "for j in range(nod):\n",
    "    c_path=os.path.join(path, dirs[j])\n",
    "    print(j)\n",
    "    print(c_path)\n",
    "    c_path, c_dirs, c_files = next(os.walk(c_path))\n",
    "    file_count = len(c_files)\n",
    "    print(file_count)\n",
    "    # create empty list\n",
    "\n",
    "    # append datasets to the list\n",
    "    for i in range(file_count):\n",
    "        temp_df = pd.read_csv(c_path + '/' + c_files[i])\n",
    "        #temp_df= temp_df.drop(['NUM','DATE'],axis=1)\n",
    "        #temp_df = df_resample(temp_df, 500) # resampling rate is 500\n",
    "        #temp_df=temp_df.drop(\"Unnamed: 0\",axis=1)\n",
    "        #temp_df.columns.str.match(\"Unnamed\")\n",
    "        temp_df=temp_df.loc[:,~temp_df.columns.str.match(\"Unnamed\")]\n",
    "\n",
    "        \n",
    "        if i % 10 == 0:  #every 10th measurement goes into the train set\n",
    "            dataframes_list_test.append(temp_df)\n",
    "            labels_list_test.append(j)\n",
    "        else:\n",
    "            dataframes_list_train.append(temp_df)\n",
    "            labels_list_train.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20bafcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1080.0\n",
       "mean      500.0\n",
       "std         0.0\n",
       "min       500.0\n",
       "25%       500.0\n",
       "50%       500.0\n",
       "75%       500.0\n",
       "max       500.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in dataframes_list_train:\n",
    "    len_sequences.append(len(one_seq))\n",
    "pd.Series(len_sequences).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e73a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(dataframes_list_train)\n",
    "#validation = np.array(dataframes_list_test)\n",
    "test = np.array(dataframes_list_test)\n",
    "train_target = np.array(labels_list_train)\n",
    "#train_target = (train_target+1)/2\n",
    "\n",
    "#validation_target = np.array(labels_list_test)\n",
    "#validation_target = (validation_target+1)/2\n",
    "\n",
    "test_target = np.array(labels_list_test)\n",
    "#test_target = (test_target+1)/2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bae414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " TIMESERIES_INPUT (InputLaye  [(None, 500, 11)]        0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " BIDIRECTIONAL_LAYER_1 (Bidi  (None, 500, 100)         24800     \n",
      " rectional)                                                      \n",
      "                                                                 \n",
      " DROPOUT_LAYER_1 (Dropout)   (None, 500, 100)          0         \n",
      "                                                                 \n",
      " BIDIRECTIONAL_LAYER_2 (Bidi  (None, 100)              60400     \n",
      " rectional)                                                      \n",
      "                                                                 \n",
      " DROPOUT_LAYER_2 (Dropout)   (None, 100)               0         \n",
      "                                                                 \n",
      " DENSE_LAYER_2 (Dense)       (None, 64)                6464      \n",
      "                                                                 \n",
      " OUTPUT_LAYER (Dense)        (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,444\n",
      "Trainable params: 92,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "# RNN Layers\n",
    "# Define input layer\n",
    "recurrent_input = Input(shape=(500,11),name='TIMESERIES_INPUT')\n",
    "\n",
    "# layer - 1\n",
    "\n",
    "rec_layer_one = Bidirectional(LSTM(50, kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01),return_sequences=True),name ='BIDIRECTIONAL_LAYER_1')(recurrent_input)\n",
    "\n",
    "rec_layer_one = Dropout(0.1,name ='DROPOUT_LAYER_1')(rec_layer_one)\n",
    "\n",
    "# layer - 2\n",
    "\n",
    "rec_layer_two = Bidirectional(LSTM(50, kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01)),name ='BIDIRECTIONAL_LAYER_2')(rec_layer_one)\n",
    "\n",
    "rec_layer_two = Dropout(0.1,name ='DROPOUT_LAYER_2')(rec_layer_two)\n",
    "\n",
    "# Combine layers - RNN + SLP\n",
    "\n",
    "combined_dense_two = Dense(64, activation='relu',name='DENSE_LAYER_2')(rec_layer_two)\n",
    "\n",
    "output = Dense(12,activation='sigmoid',name='OUTPUT_LAYER')(combined_dense_two)\n",
    "\n",
    "# Compile Model\n",
    "\n",
    "model1 = Model(inputs=[recurrent_input],outputs=[output])\n",
    "\n",
    "# binary cross entropy loss\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "# focal loss\n",
    "\n",
    "def focal_loss_custom(alpha, gamma):\n",
    "\n",
    "    def binary_focal_loss(y_true, y_pred):\n",
    "\n",
    "        fl = tfa.losses.SigmoidFocalCrossEntropy(alpha=alpha, gamma=gamma)\n",
    "\n",
    "        y_true_K = K.ones_like(y_true)\n",
    "\n",
    "        focal_loss = fl(y_true, y_pred)\n",
    "\n",
    "        return focal_loss\n",
    "\n",
    "    return binary_focal_loss\n",
    "\n",
    "model1.compile(loss=focal_loss_custom(alpha=0.2, gamma=2.0), optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b792cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics for evaluating the model - recall, precision and f1-score\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "   possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "   recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "   return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "\n",
    "   true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "   predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "   precision = true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "   return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "\n",
    "   precision = precision_m(y_true, y_pred)\n",
    "\n",
    "   recall = recall_m(y_true, y_pred)\n",
    "\n",
    "   return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a50e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 37s 1s/step - loss: -323308.0312 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0750 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0000 - accuracy: 0.0671 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.0625 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0000 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0312 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0000 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.0625 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0625 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.0625 - accuracy: 0.0706 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6562 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.0625 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6562 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0625 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6562 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0625 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0312 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.0625 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.0625 - accuracy: 0.0891 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.1250 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.1250 - accuracy: 0.0694 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.1250 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.1250 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.1250 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.6875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.1562 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7188 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.1250 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7188 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.1562 - accuracy: 0.0868 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 19s 1s/step - loss: -323308.1562 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.1562 - accuracy: 0.0926 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 19s 1s/step - loss: -323308.1562 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1562 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1562 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.1875 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1875 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.1562 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.7812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1562 - accuracy: 0.0856 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8125 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1875 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8125 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.1875 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.2500 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2188 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2188 - accuracy: 0.0683 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.2188 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2500 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2188 - accuracy: 0.0880 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2500 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2500 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8750 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2500 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.8750 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2500 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.2500 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2500 - accuracy: 0.0880 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2500 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2812 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.2812 - accuracy: 0.0706 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.2812 - accuracy: 0.0694 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.2812 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.3438 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 20s 1s/step - loss: -323308.3438 - accuracy: 0.0903 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9375 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.3438 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9375 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 19s 1s/step - loss: -323308.2812 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 19s 1s/step - loss: -323308.3438 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 19s 1s/step - loss: -323308.3438 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.3438 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3438 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.3438 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3750 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3750 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3750 - accuracy: 0.0637 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316199.9688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4062 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0000 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3750 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0000 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.3750 - accuracy: 0.0856 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.3750 - accuracy: 0.0694 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.4375 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.4062 - accuracy: 0.0671 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.4062 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.3750 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4062 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4062 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4375 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4375 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4375 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.4062 - accuracy: 0.0868 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4375 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4375 - accuracy: 0.0961 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 21s 1s/step - loss: -323308.4375 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4688 - accuracy: 0.0637 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4688 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.4688 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.4688 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.5312 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.4688 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.4688 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.0938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.5312 - accuracy: 0.0660 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5312 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5625 - accuracy: 0.0683 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5312 - accuracy: 0.0706 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5625 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5312 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5625 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5625 - accuracy: 0.0880 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5938 - accuracy: 0.0683 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1250 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5625 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1562 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5625 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1562 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5938 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5938 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5938 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5625 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.5938 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5938 - accuracy: 0.0856 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.5938 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 21s 2s/step - loss: -323308.6250 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.6250 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.1875 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.6250 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2188 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 20s 1s/step - loss: -323308.6250 - accuracy: 0.0903 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2188 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 22s 2s/step - loss: -323308.6250 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.6250 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.6562 - accuracy: 0.0868 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.6562 - accuracy: 0.0891 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 28s 2s/step - loss: -323308.6562 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 27s 2s/step - loss: -323308.6562 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 27s 2s/step - loss: -323308.6250 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.6562 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.6562 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 23s 2s/step - loss: -323308.6562 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.2812 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 24s 2s/step - loss: -323308.7188 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3125 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 27s 2s/step - loss: -323308.7188 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3125 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.6562 - accuracy: 0.0660 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7188 - accuracy: 0.0833 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7188 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7500 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7188 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 26s 2s/step - loss: -323308.7188 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7188 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7500 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 25s 2s/step - loss: -323308.7812 - accuracy: 0.0868 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7188 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3438 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7500 - accuracy: 0.0880 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3750 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.3750 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 16s 1s/step - loss: -323308.7812 - accuracy: 0.0856 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.7812 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8125 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.7812 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4062 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8438 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4375 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8125 - accuracy: 0.0671 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4375 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8438 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 15s 1s/step - loss: -323308.8125 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8125 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8438 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8125 - accuracy: 0.0822 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8125 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8438 - accuracy: 0.0718 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8438 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8750 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.4688 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8750 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5000 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8438 - accuracy: 0.0706 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5000 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8750 - accuracy: 0.0694 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5000 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.8750 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8750 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8750 - accuracy: 0.0706 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.8750 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8750 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 16s 1s/step - loss: -323308.8750 - accuracy: 0.0741 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0683 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0810 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.9375 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0752 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5312 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323308.9375 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323309.0000 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9375 - accuracy: 0.0787 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9688 - accuracy: 0.0729 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323309.0000 - accuracy: 0.0694 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323309.0000 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9688 - accuracy: 0.0845 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323309.0000 - accuracy: 0.0799 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323309.0000 - accuracy: 0.0764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5625 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323308.9688 - accuracy: 0.0856 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 17s 1s/step - loss: -323309.0000 - accuracy: 0.0648 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 18s 1s/step - loss: -323309.0000 - accuracy: 0.0775 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: -316200.5938 - val_accuracy: 0.0833 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 182/200\n",
      " 8/14 [================>.............] - ETA: 8s - loss: -328107.6562 - accuracy: 0.0703 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m history1 \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "\n",
    "\n",
    "history1 =  model1.fit(train, train_target, epochs=200, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0936805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "\n",
    "\n",
    "history1 =  model1.fit([train], train_target, epochs=200, batch_size=64, verbose=1, validation_data=([test],test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14180136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "\n",
    "\n",
    "history =  model.fit([train], train_target, epochs=200, batch_size=64, verbose=1, validation_data=([test],test_target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    train,\n",
    "    train_target,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#evaluate model\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate([np.asarray(test).astype('float32')], test_target, batch_size=32, verbose=0)\n",
    "\n",
    "#print output\n",
    "\n",
    "print(\"Accuracy:{} , F1_Score:{}, Precision:{}, Recall:{}\".format(accuracy, f1_score, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe20c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history1.history['sparse_categorical_accuracy'])\n",
    "\n",
    "plt.plot(history1.history['val_sparse_categorical_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history1.history['loss'])\n",
    "\n",
    "plt.plot(history1.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#evaluate model\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate([np.asarray(test).astype('float32')], test_target, batch_size=32, verbose=0)\n",
    "\n",
    "#print output\n",
    "\n",
    "print(\"Accuracy:{} , F1_Score:{}, Precision:{}, Recall:{}\".format(accuracy, f1_score, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689331e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c206e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84281edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(100, input_shape = (500, 11)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(loss=\"binary_crossentropy\", metrics=[keras.metrics.binary_accuracy], optimizer=\"adam\")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train, train_target, batch_size=64, epochs=50,validation_data=(test,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca634c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8978995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60244233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_target = shuffle(train, train_target)\n",
    "test, test_target = shuffle(test, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "872a91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(np.unique(train_target))\n",
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    #conv1 = keras.layers.Dropout(0.1)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "    #conv2 = keras.layers.Dropout(0.1)(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model3 = make_model(input_shape=train.shape[1:])\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef47ce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "14/14 [==============================] - 23s 485ms/step - loss: 2.4439 - sparse_categorical_accuracy: 0.1088 - val_loss: 2.9026 - val_sparse_categorical_accuracy: 0.0880 - lr: 0.0010\n",
      "Epoch 2/400\n",
      "14/14 [==============================] - 6s 460ms/step - loss: 2.2878 - sparse_categorical_accuracy: 0.2106 - val_loss: 2.6022 - val_sparse_categorical_accuracy: 0.0648 - lr: 0.0010\n",
      "Epoch 3/400\n",
      "14/14 [==============================] - 6s 461ms/step - loss: 2.2020 - sparse_categorical_accuracy: 0.2442 - val_loss: 2.4893 - val_sparse_categorical_accuracy: 0.0880 - lr: 0.0010\n",
      "Epoch 4/400\n",
      "14/14 [==============================] - 6s 455ms/step - loss: 2.0783 - sparse_categorical_accuracy: 0.2870 - val_loss: 2.3797 - val_sparse_categorical_accuracy: 0.1111 - lr: 0.0010\n",
      "Epoch 5/400\n",
      "14/14 [==============================] - 6s 445ms/step - loss: 1.9991 - sparse_categorical_accuracy: 0.2951 - val_loss: 2.2899 - val_sparse_categorical_accuracy: 0.1852 - lr: 0.0010\n",
      "Epoch 6/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.8978 - sparse_categorical_accuracy: 0.3438 - val_loss: 2.2270 - val_sparse_categorical_accuracy: 0.2361 - lr: 0.0010\n",
      "Epoch 7/400\n",
      "14/14 [==============================] - 6s 448ms/step - loss: 1.8413 - sparse_categorical_accuracy: 0.3519 - val_loss: 2.1628 - val_sparse_categorical_accuracy: 0.1944 - lr: 0.0010\n",
      "Epoch 8/400\n",
      "14/14 [==============================] - 6s 452ms/step - loss: 1.7943 - sparse_categorical_accuracy: 0.3785 - val_loss: 2.0915 - val_sparse_categorical_accuracy: 0.2685 - lr: 0.0010\n",
      "Epoch 9/400\n",
      "14/14 [==============================] - 6s 448ms/step - loss: 1.7384 - sparse_categorical_accuracy: 0.4074 - val_loss: 2.0447 - val_sparse_categorical_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 10/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 1.7140 - sparse_categorical_accuracy: 0.4074 - val_loss: 2.0502 - val_sparse_categorical_accuracy: 0.2963 - lr: 0.0010\n",
      "Epoch 11/400\n",
      "14/14 [==============================] - 6s 444ms/step - loss: 1.6676 - sparse_categorical_accuracy: 0.4479 - val_loss: 2.0039 - val_sparse_categorical_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 12/400\n",
      "14/14 [==============================] - 6s 445ms/step - loss: 1.6204 - sparse_categorical_accuracy: 0.4410 - val_loss: 1.9116 - val_sparse_categorical_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 13/400\n",
      "14/14 [==============================] - 7s 466ms/step - loss: 1.5863 - sparse_categorical_accuracy: 0.4792 - val_loss: 1.9011 - val_sparse_categorical_accuracy: 0.3935 - lr: 0.0010\n",
      "Epoch 14/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 1.5693 - sparse_categorical_accuracy: 0.4641 - val_loss: 1.9081 - val_sparse_categorical_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 15/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.5424 - sparse_categorical_accuracy: 0.4711 - val_loss: 1.8118 - val_sparse_categorical_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 16/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.5074 - sparse_categorical_accuracy: 0.4815 - val_loss: 1.8035 - val_sparse_categorical_accuracy: 0.4537 - lr: 0.0010\n",
      "Epoch 17/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.4772 - sparse_categorical_accuracy: 0.4815 - val_loss: 1.7780 - val_sparse_categorical_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 18/400\n",
      "14/14 [==============================] - 6s 459ms/step - loss: 1.4688 - sparse_categorical_accuracy: 0.4907 - val_loss: 1.7435 - val_sparse_categorical_accuracy: 0.4491 - lr: 0.0010\n",
      "Epoch 19/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 1.4376 - sparse_categorical_accuracy: 0.5208 - val_loss: 1.7501 - val_sparse_categorical_accuracy: 0.4213 - lr: 0.0010\n",
      "Epoch 20/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.4075 - sparse_categorical_accuracy: 0.5139 - val_loss: 1.7294 - val_sparse_categorical_accuracy: 0.4028 - lr: 0.0010\n",
      "Epoch 21/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 1.3937 - sparse_categorical_accuracy: 0.5359 - val_loss: 1.7409 - val_sparse_categorical_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 22/400\n",
      "14/14 [==============================] - 6s 448ms/step - loss: 1.3700 - sparse_categorical_accuracy: 0.5324 - val_loss: 1.7117 - val_sparse_categorical_accuracy: 0.4352 - lr: 0.0010\n",
      "Epoch 23/400\n",
      "14/14 [==============================] - 6s 444ms/step - loss: 1.3573 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.7766 - val_sparse_categorical_accuracy: 0.4028 - lr: 0.0010\n",
      "Epoch 24/400\n",
      "14/14 [==============================] - 6s 441ms/step - loss: 1.3887 - sparse_categorical_accuracy: 0.5139 - val_loss: 1.6691 - val_sparse_categorical_accuracy: 0.4398 - lr: 0.0010\n",
      "Epoch 25/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 1.3509 - sparse_categorical_accuracy: 0.5336 - val_loss: 1.6841 - val_sparse_categorical_accuracy: 0.4491 - lr: 0.0010\n",
      "Epoch 26/400\n",
      "14/14 [==============================] - 6s 449ms/step - loss: 1.3707 - sparse_categorical_accuracy: 0.5069 - val_loss: 1.6582 - val_sparse_categorical_accuracy: 0.4120 - lr: 0.0010\n",
      "Epoch 27/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 1.3431 - sparse_categorical_accuracy: 0.5475 - val_loss: 1.7246 - val_sparse_categorical_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 28/400\n",
      "14/14 [==============================] - 6s 457ms/step - loss: 1.2786 - sparse_categorical_accuracy: 0.5741 - val_loss: 1.6194 - val_sparse_categorical_accuracy: 0.4120 - lr: 0.0010\n",
      "Epoch 29/400\n",
      "14/14 [==============================] - 6s 446ms/step - loss: 1.2616 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.5830 - val_sparse_categorical_accuracy: 0.4537 - lr: 0.0010\n",
      "Epoch 30/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 1.2448 - sparse_categorical_accuracy: 0.5671 - val_loss: 1.6512 - val_sparse_categorical_accuracy: 0.4213 - lr: 0.0010\n",
      "Epoch 31/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 1.2635 - sparse_categorical_accuracy: 0.5660 - val_loss: 1.6518 - val_sparse_categorical_accuracy: 0.4583 - lr: 0.0010\n",
      "Epoch 32/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 1.2757 - sparse_categorical_accuracy: 0.5521 - val_loss: 1.6807 - val_sparse_categorical_accuracy: 0.4491 - lr: 0.0010\n",
      "Epoch 33/400\n",
      "14/14 [==============================] - 6s 442ms/step - loss: 1.2148 - sparse_categorical_accuracy: 0.5880 - val_loss: 1.5952 - val_sparse_categorical_accuracy: 0.4583 - lr: 0.0010\n",
      "Epoch 34/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 1.1972 - sparse_categorical_accuracy: 0.5984 - val_loss: 1.5999 - val_sparse_categorical_accuracy: 0.4491 - lr: 0.0010\n",
      "Epoch 35/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 1.1996 - sparse_categorical_accuracy: 0.5694 - val_loss: 1.6587 - val_sparse_categorical_accuracy: 0.4306 - lr: 0.0010\n",
      "Epoch 36/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 1.2164 - sparse_categorical_accuracy: 0.5799 - val_loss: 1.6373 - val_sparse_categorical_accuracy: 0.4630 - lr: 0.0010\n",
      "Epoch 37/400\n",
      "14/14 [==============================] - 6s 465ms/step - loss: 1.2006 - sparse_categorical_accuracy: 0.5845 - val_loss: 1.6007 - val_sparse_categorical_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 38/400\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 1.1469 - sparse_categorical_accuracy: 0.5903 - val_loss: 1.6013 - val_sparse_categorical_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 39/400\n",
      "14/14 [==============================] - 6s 451ms/step - loss: 1.1467 - sparse_categorical_accuracy: 0.6007 - val_loss: 1.5520 - val_sparse_categorical_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 40/400\n",
      "14/14 [==============================] - 6s 453ms/step - loss: 1.1048 - sparse_categorical_accuracy: 0.6389 - val_loss: 1.5323 - val_sparse_categorical_accuracy: 0.5139 - lr: 0.0010\n",
      "Epoch 41/400\n",
      "14/14 [==============================] - 6s 448ms/step - loss: 1.1254 - sparse_categorical_accuracy: 0.6169 - val_loss: 1.5454 - val_sparse_categorical_accuracy: 0.5139 - lr: 0.0010\n",
      "Epoch 42/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 1.1213 - sparse_categorical_accuracy: 0.6204 - val_loss: 1.5674 - val_sparse_categorical_accuracy: 0.5093 - lr: 0.0010\n",
      "Epoch 43/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 6s 444ms/step - loss: 1.0822 - sparse_categorical_accuracy: 0.6366 - val_loss: 1.5550 - val_sparse_categorical_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 44/400\n",
      "14/14 [==============================] - 6s 450ms/step - loss: 1.0663 - sparse_categorical_accuracy: 0.6481 - val_loss: 1.5310 - val_sparse_categorical_accuracy: 0.4769 - lr: 0.0010\n",
      "Epoch 45/400\n",
      "14/14 [==============================] - 6s 443ms/step - loss: 1.0952 - sparse_categorical_accuracy: 0.6366 - val_loss: 1.5431 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 46/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 1.0711 - sparse_categorical_accuracy: 0.6505 - val_loss: 1.5947 - val_sparse_categorical_accuracy: 0.4537 - lr: 0.0010\n",
      "Epoch 47/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 1.0285 - sparse_categorical_accuracy: 0.6620 - val_loss: 1.6112 - val_sparse_categorical_accuracy: 0.4583 - lr: 0.0010\n",
      "Epoch 48/400\n",
      "14/14 [==============================] - 6s 464ms/step - loss: 1.0427 - sparse_categorical_accuracy: 0.6470 - val_loss: 1.4987 - val_sparse_categorical_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 49/400\n",
      "14/14 [==============================] - 6s 454ms/step - loss: 1.0424 - sparse_categorical_accuracy: 0.6389 - val_loss: 1.4394 - val_sparse_categorical_accuracy: 0.5509 - lr: 0.0010\n",
      "Epoch 50/400\n",
      "14/14 [==============================] - 6s 444ms/step - loss: 1.0031 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.4302 - val_sparse_categorical_accuracy: 0.5370 - lr: 0.0010\n",
      "Epoch 51/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 1.0042 - sparse_categorical_accuracy: 0.6678 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.5602 - lr: 0.0010\n",
      "Epoch 52/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.9841 - sparse_categorical_accuracy: 0.6852 - val_loss: 1.4460 - val_sparse_categorical_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 53/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.9719 - sparse_categorical_accuracy: 0.6725 - val_loss: 1.5284 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 54/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.9866 - sparse_categorical_accuracy: 0.6690 - val_loss: 1.4548 - val_sparse_categorical_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 55/400\n",
      "14/14 [==============================] - 6s 431ms/step - loss: 1.0245 - sparse_categorical_accuracy: 0.6470 - val_loss: 1.4489 - val_sparse_categorical_accuracy: 0.5648 - lr: 0.0010\n",
      "Epoch 56/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.9765 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.5174 - val_sparse_categorical_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 57/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 0.9778 - sparse_categorical_accuracy: 0.6644 - val_loss: 1.4839 - val_sparse_categorical_accuracy: 0.5509 - lr: 0.0010\n",
      "Epoch 58/400\n",
      "14/14 [==============================] - 6s 440ms/step - loss: 0.9329 - sparse_categorical_accuracy: 0.6968 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.5463 - lr: 0.0010\n",
      "Epoch 59/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.9027 - sparse_categorical_accuracy: 0.7106 - val_loss: 1.4844 - val_sparse_categorical_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 60/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.9369 - sparse_categorical_accuracy: 0.6817 - val_loss: 1.5524 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 61/400\n",
      "14/14 [==============================] - 6s 453ms/step - loss: 0.9110 - sparse_categorical_accuracy: 0.6898 - val_loss: 1.4245 - val_sparse_categorical_accuracy: 0.5463 - lr: 0.0010\n",
      "Epoch 62/400\n",
      "14/14 [==============================] - 6s 454ms/step - loss: 0.9372 - sparse_categorical_accuracy: 0.6956 - val_loss: 1.4571 - val_sparse_categorical_accuracy: 0.5370 - lr: 0.0010\n",
      "Epoch 63/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.8928 - sparse_categorical_accuracy: 0.6991 - val_loss: 1.4247 - val_sparse_categorical_accuracy: 0.5648 - lr: 0.0010\n",
      "Epoch 64/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.9048 - sparse_categorical_accuracy: 0.6921 - val_loss: 1.4442 - val_sparse_categorical_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 65/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.8975 - sparse_categorical_accuracy: 0.7106 - val_loss: 1.4546 - val_sparse_categorical_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 66/400\n",
      "14/14 [==============================] - 6s 431ms/step - loss: 0.8762 - sparse_categorical_accuracy: 0.7222 - val_loss: 1.4371 - val_sparse_categorical_accuracy: 0.5417 - lr: 0.0010\n",
      "Epoch 67/400\n",
      "14/14 [==============================] - 6s 420ms/step - loss: 0.8562 - sparse_categorical_accuracy: 0.7234 - val_loss: 1.4694 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 68/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.8625 - sparse_categorical_accuracy: 0.7118 - val_loss: 1.4925 - val_sparse_categorical_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 69/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.8399 - sparse_categorical_accuracy: 0.7245 - val_loss: 1.4629 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 70/400\n",
      "14/14 [==============================] - 9s 627ms/step - loss: 0.8435 - sparse_categorical_accuracy: 0.7257 - val_loss: 1.3659 - val_sparse_categorical_accuracy: 0.5741 - lr: 0.0010\n",
      "Epoch 71/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.8307 - sparse_categorical_accuracy: 0.7141 - val_loss: 1.4743 - val_sparse_categorical_accuracy: 0.5509 - lr: 0.0010\n",
      "Epoch 72/400\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.8435 - sparse_categorical_accuracy: 0.7083 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 73/400\n",
      "14/14 [==============================] - 6s 444ms/step - loss: 0.8568 - sparse_categorical_accuracy: 0.7083 - val_loss: 1.6162 - val_sparse_categorical_accuracy: 0.5139 - lr: 0.0010\n",
      "Epoch 74/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.8254 - sparse_categorical_accuracy: 0.7303 - val_loss: 1.4649 - val_sparse_categorical_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 75/400\n",
      "14/14 [==============================] - 6s 431ms/step - loss: 0.8016 - sparse_categorical_accuracy: 0.7373 - val_loss: 1.4340 - val_sparse_categorical_accuracy: 0.6065 - lr: 0.0010\n",
      "Epoch 76/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.7477 - val_loss: 1.4056 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 77/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.7676 - sparse_categorical_accuracy: 0.7569 - val_loss: 1.4022 - val_sparse_categorical_accuracy: 0.6065 - lr: 0.0010\n",
      "Epoch 78/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.7719 - sparse_categorical_accuracy: 0.7569 - val_loss: 1.3974 - val_sparse_categorical_accuracy: 0.6065 - lr: 0.0010\n",
      "Epoch 79/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.7757 - sparse_categorical_accuracy: 0.7361 - val_loss: 1.5683 - val_sparse_categorical_accuracy: 0.5046 - lr: 0.0010\n",
      "Epoch 80/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.7429 - sparse_categorical_accuracy: 0.7766 - val_loss: 1.4734 - val_sparse_categorical_accuracy: 0.5417 - lr: 0.0010\n",
      "Epoch 81/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.7475 - sparse_categorical_accuracy: 0.7639 - val_loss: 1.4223 - val_sparse_categorical_accuracy: 0.5648 - lr: 0.0010\n",
      "Epoch 82/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.7237 - sparse_categorical_accuracy: 0.7604 - val_loss: 1.4421 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 83/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.7564 - sparse_categorical_accuracy: 0.7604 - val_loss: 1.5119 - val_sparse_categorical_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 84/400\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 0.7675 - sparse_categorical_accuracy: 0.7454 - val_loss: 1.3456 - val_sparse_categorical_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 85/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 6s 441ms/step - loss: 0.7313 - sparse_categorical_accuracy: 0.7639 - val_loss: 1.4586 - val_sparse_categorical_accuracy: 0.5093 - lr: 0.0010\n",
      "Epoch 86/400\n",
      "14/14 [==============================] - 6s 461ms/step - loss: 0.6989 - sparse_categorical_accuracy: 0.7986 - val_loss: 1.4822 - val_sparse_categorical_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 87/400\n",
      "14/14 [==============================] - 7s 467ms/step - loss: 0.7021 - sparse_categorical_accuracy: 0.7720 - val_loss: 1.4058 - val_sparse_categorical_accuracy: 0.5926 - lr: 0.0010\n",
      "Epoch 88/400\n",
      "14/14 [==============================] - 6s 448ms/step - loss: 0.7285 - sparse_categorical_accuracy: 0.7627 - val_loss: 1.5195 - val_sparse_categorical_accuracy: 0.5370 - lr: 0.0010\n",
      "Epoch 89/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.7720 - val_loss: 1.5105 - val_sparse_categorical_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 90/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.7812 - val_loss: 1.5441 - val_sparse_categorical_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 91/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.6733 - sparse_categorical_accuracy: 0.7766 - val_loss: 1.4075 - val_sparse_categorical_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 92/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.3894 - val_sparse_categorical_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 93/400\n",
      "14/14 [==============================] - 6s 442ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7894 - val_loss: 1.3866 - val_sparse_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 94/400\n",
      "14/14 [==============================] - 6s 449ms/step - loss: 0.6821 - sparse_categorical_accuracy: 0.7639 - val_loss: 1.3429 - val_sparse_categorical_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 95/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.6521 - sparse_categorical_accuracy: 0.7917 - val_loss: 1.3714 - val_sparse_categorical_accuracy: 0.6157 - lr: 0.0010\n",
      "Epoch 96/400\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 0.6366 - sparse_categorical_accuracy: 0.8113 - val_loss: 1.3355 - val_sparse_categorical_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 97/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.8148 - val_loss: 1.3703 - val_sparse_categorical_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 98/400\n",
      "14/14 [==============================] - 6s 455ms/step - loss: 0.6284 - sparse_categorical_accuracy: 0.8032 - val_loss: 1.5083 - val_sparse_categorical_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 99/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 0.6677 - sparse_categorical_accuracy: 0.7940 - val_loss: 1.6129 - val_sparse_categorical_accuracy: 0.4954 - lr: 0.0010\n",
      "Epoch 100/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.4566 - val_sparse_categorical_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 101/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7847 - val_loss: 1.6065 - val_sparse_categorical_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 102/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.6177 - sparse_categorical_accuracy: 0.8090 - val_loss: 1.4582 - val_sparse_categorical_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 103/400\n",
      "14/14 [==============================] - 6s 444ms/step - loss: 0.5951 - sparse_categorical_accuracy: 0.8160 - val_loss: 1.5419 - val_sparse_categorical_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 104/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.7801 - val_loss: 1.6290 - val_sparse_categorical_accuracy: 0.5370 - lr: 0.0010\n",
      "Epoch 105/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.5870 - sparse_categorical_accuracy: 0.8125 - val_loss: 1.5957 - val_sparse_categorical_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 106/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.7743 - val_loss: 1.5201 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 107/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.6273 - sparse_categorical_accuracy: 0.8079 - val_loss: 1.4480 - val_sparse_categorical_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 108/400\n",
      "14/14 [==============================] - 6s 445ms/step - loss: 0.6137 - sparse_categorical_accuracy: 0.8032 - val_loss: 1.5641 - val_sparse_categorical_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 109/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.7940 - val_loss: 1.5769 - val_sparse_categorical_accuracy: 0.5741 - lr: 0.0010\n",
      "Epoch 110/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.6092 - sparse_categorical_accuracy: 0.8113 - val_loss: 1.5101 - val_sparse_categorical_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 111/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.5743 - sparse_categorical_accuracy: 0.8287 - val_loss: 1.4792 - val_sparse_categorical_accuracy: 0.6065 - lr: 0.0010\n",
      "Epoch 112/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.5596 - sparse_categorical_accuracy: 0.8322 - val_loss: 1.4900 - val_sparse_categorical_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 113/400\n",
      "14/14 [==============================] - 6s 440ms/step - loss: 0.5970 - sparse_categorical_accuracy: 0.8079 - val_loss: 1.5897 - val_sparse_categorical_accuracy: 0.5509 - lr: 0.0010\n",
      "Epoch 114/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8160 - val_loss: 1.5598 - val_sparse_categorical_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 115/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.8438 - val_loss: 1.4026 - val_sparse_categorical_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 116/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.8148 - val_loss: 1.4285 - val_sparse_categorical_accuracy: 0.6065 - lr: 0.0010\n",
      "Epoch 117/400\n",
      "14/14 [==============================] - 6s 443ms/step - loss: 0.5147 - sparse_categorical_accuracy: 0.8519 - val_loss: 1.3319 - val_sparse_categorical_accuracy: 0.5926 - lr: 5.0000e-04\n",
      "Epoch 118/400\n",
      "14/14 [==============================] - 6s 442ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.8715 - val_loss: 1.3513 - val_sparse_categorical_accuracy: 0.6296 - lr: 5.0000e-04\n",
      "Epoch 119/400\n",
      "14/14 [==============================] - 6s 440ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8843 - val_loss: 1.3826 - val_sparse_categorical_accuracy: 0.6204 - lr: 5.0000e-04\n",
      "Epoch 120/400\n",
      "14/14 [==============================] - 6s 434ms/step - loss: 0.4397 - sparse_categorical_accuracy: 0.8819 - val_loss: 1.3866 - val_sparse_categorical_accuracy: 0.6111 - lr: 5.0000e-04\n",
      "Epoch 121/400\n",
      "14/14 [==============================] - 6s 430ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.8831 - val_loss: 1.3896 - val_sparse_categorical_accuracy: 0.6065 - lr: 5.0000e-04\n",
      "Epoch 122/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8819 - val_loss: 1.3654 - val_sparse_categorical_accuracy: 0.6157 - lr: 5.0000e-04\n",
      "Epoch 123/400\n",
      "14/14 [==============================] - 6s 445ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8808 - val_loss: 1.3434 - val_sparse_categorical_accuracy: 0.6111 - lr: 5.0000e-04\n",
      "Epoch 124/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.4255 - sparse_categorical_accuracy: 0.8808 - val_loss: 1.4401 - val_sparse_categorical_accuracy: 0.6019 - lr: 5.0000e-04\n",
      "Epoch 125/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.4362 - sparse_categorical_accuracy: 0.8727 - val_loss: 1.3717 - val_sparse_categorical_accuracy: 0.6204 - lr: 5.0000e-04\n",
      "Epoch 126/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.4457 - sparse_categorical_accuracy: 0.8750 - val_loss: 1.3781 - val_sparse_categorical_accuracy: 0.5926 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.4167 - sparse_categorical_accuracy: 0.8947 - val_loss: 1.3823 - val_sparse_categorical_accuracy: 0.6343 - lr: 5.0000e-04\n",
      "Epoch 128/400\n",
      "14/14 [==============================] - 6s 441ms/step - loss: 0.4377 - sparse_categorical_accuracy: 0.8773 - val_loss: 1.4735 - val_sparse_categorical_accuracy: 0.6343 - lr: 5.0000e-04\n",
      "Epoch 129/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.4652 - sparse_categorical_accuracy: 0.8750 - val_loss: 1.4150 - val_sparse_categorical_accuracy: 0.6204 - lr: 5.0000e-04\n",
      "Epoch 130/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 0.4340 - sparse_categorical_accuracy: 0.8866 - val_loss: 1.4394 - val_sparse_categorical_accuracy: 0.5880 - lr: 5.0000e-04\n",
      "Epoch 131/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.4175 - sparse_categorical_accuracy: 0.8819 - val_loss: 1.3996 - val_sparse_categorical_accuracy: 0.6019 - lr: 5.0000e-04\n",
      "Epoch 132/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.4138 - sparse_categorical_accuracy: 0.8993 - val_loss: 1.3765 - val_sparse_categorical_accuracy: 0.6065 - lr: 5.0000e-04\n",
      "Epoch 133/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.8900 - val_loss: 1.4084 - val_sparse_categorical_accuracy: 0.6111 - lr: 5.0000e-04\n",
      "Epoch 134/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.4151 - sparse_categorical_accuracy: 0.8785 - val_loss: 1.3324 - val_sparse_categorical_accuracy: 0.6250 - lr: 5.0000e-04\n",
      "Epoch 135/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3864 - sparse_categorical_accuracy: 0.8993 - val_loss: 1.3894 - val_sparse_categorical_accuracy: 0.6250 - lr: 5.0000e-04\n",
      "Epoch 136/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8958 - val_loss: 1.4400 - val_sparse_categorical_accuracy: 0.6204 - lr: 5.0000e-04\n",
      "Epoch 137/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.3980 - sparse_categorical_accuracy: 0.8924 - val_loss: 1.3697 - val_sparse_categorical_accuracy: 0.6343 - lr: 5.0000e-04\n",
      "Epoch 138/400\n",
      "14/14 [==============================] - 6s 442ms/step - loss: 0.3725 - sparse_categorical_accuracy: 0.9039 - val_loss: 1.3937 - val_sparse_categorical_accuracy: 0.6157 - lr: 2.5000e-04\n",
      "Epoch 139/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.3653 - sparse_categorical_accuracy: 0.9039 - val_loss: 1.3644 - val_sparse_categorical_accuracy: 0.6250 - lr: 2.5000e-04\n",
      "Epoch 140/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.3449 - sparse_categorical_accuracy: 0.9248 - val_loss: 1.3730 - val_sparse_categorical_accuracy: 0.6157 - lr: 2.5000e-04\n",
      "Epoch 141/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3460 - sparse_categorical_accuracy: 0.9167 - val_loss: 1.3560 - val_sparse_categorical_accuracy: 0.6250 - lr: 2.5000e-04\n",
      "Epoch 142/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3490 - sparse_categorical_accuracy: 0.9155 - val_loss: 1.3509 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 143/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.3574 - sparse_categorical_accuracy: 0.9167 - val_loss: 1.3921 - val_sparse_categorical_accuracy: 0.6065 - lr: 2.5000e-04\n",
      "Epoch 144/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3450 - sparse_categorical_accuracy: 0.9178 - val_loss: 1.3664 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 145/400\n",
      "14/14 [==============================] - 6s 438ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.9062 - val_loss: 1.3543 - val_sparse_categorical_accuracy: 0.6065 - lr: 2.5000e-04\n",
      "Epoch 146/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.9097 - val_loss: 1.3796 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 147/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.3378 - sparse_categorical_accuracy: 0.9167 - val_loss: 1.3892 - val_sparse_categorical_accuracy: 0.5972 - lr: 2.5000e-04\n",
      "Epoch 148/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.8993 - val_loss: 1.3584 - val_sparse_categorical_accuracy: 0.6204 - lr: 2.5000e-04\n",
      "Epoch 149/400\n",
      "14/14 [==============================] - 6s 440ms/step - loss: 0.3606 - sparse_categorical_accuracy: 0.9074 - val_loss: 1.4256 - val_sparse_categorical_accuracy: 0.6065 - lr: 2.5000e-04\n",
      "Epoch 150/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.3407 - sparse_categorical_accuracy: 0.9294 - val_loss: 1.3740 - val_sparse_categorical_accuracy: 0.6157 - lr: 2.5000e-04\n",
      "Epoch 151/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3482 - sparse_categorical_accuracy: 0.9190 - val_loss: 1.3462 - val_sparse_categorical_accuracy: 0.5972 - lr: 2.5000e-04\n",
      "Epoch 152/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.9132 - val_loss: 1.3953 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 153/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.3583 - sparse_categorical_accuracy: 0.9005 - val_loss: 1.3928 - val_sparse_categorical_accuracy: 0.6250 - lr: 2.5000e-04\n",
      "Epoch 154/400\n",
      "14/14 [==============================] - 6s 443ms/step - loss: 0.3386 - sparse_categorical_accuracy: 0.9190 - val_loss: 1.3705 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 155/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9201 - val_loss: 1.3837 - val_sparse_categorical_accuracy: 0.6065 - lr: 2.5000e-04\n",
      "Epoch 156/400\n",
      "14/14 [==============================] - 6s 433ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.4152 - val_sparse_categorical_accuracy: 0.6111 - lr: 2.5000e-04\n",
      "Epoch 157/400\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.3323 - sparse_categorical_accuracy: 0.9248 - val_loss: 1.3744 - val_sparse_categorical_accuracy: 0.6065 - lr: 2.5000e-04\n",
      "Epoch 158/400\n",
      "14/14 [==============================] - 6s 443ms/step - loss: 0.3235 - sparse_categorical_accuracy: 0.9306 - val_loss: 1.3706 - val_sparse_categorical_accuracy: 0.6019 - lr: 1.2500e-04\n",
      "Epoch 159/400\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.3120 - sparse_categorical_accuracy: 0.9271 - val_loss: 1.3995 - val_sparse_categorical_accuracy: 0.5972 - lr: 1.2500e-04\n",
      "Epoch 160/400\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.3242 - sparse_categorical_accuracy: 0.9190 - val_loss: 1.3741 - val_sparse_categorical_accuracy: 0.6019 - lr: 1.2500e-04\n",
      "Epoch 161/400\n",
      "14/14 [==============================] - 6s 460ms/step - loss: 0.3171 - sparse_categorical_accuracy: 0.9294 - val_loss: 1.3781 - val_sparse_categorical_accuracy: 0.6065 - lr: 1.2500e-04\n",
      "Epoch 162/400\n",
      "14/14 [==============================] - 6s 443ms/step - loss: 0.3028 - sparse_categorical_accuracy: 0.9340 - val_loss: 1.3567 - val_sparse_categorical_accuracy: 0.6019 - lr: 1.2500e-04\n",
      "Epoch 163/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.3289 - sparse_categorical_accuracy: 0.9155 - val_loss: 1.3786 - val_sparse_categorical_accuracy: 0.6019 - lr: 1.2500e-04\n",
      "Epoch 164/400\n",
      "14/14 [==============================] - 6s 441ms/step - loss: 0.3102 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.3457 - val_sparse_categorical_accuracy: 0.5972 - lr: 1.2500e-04\n",
      "Epoch 165/400\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.2980 - sparse_categorical_accuracy: 0.9340 - val_loss: 1.3802 - val_sparse_categorical_accuracy: 0.6157 - lr: 1.2500e-04\n",
      "Epoch 166/400\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.3070 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3632 - val_sparse_categorical_accuracy: 0.6019 - lr: 1.2500e-04\n",
      "Epoch 167/400\n",
      "14/14 [==============================] - 6s 435ms/step - loss: 0.2972 - sparse_categorical_accuracy: 0.9433 - val_loss: 1.3664 - val_sparse_categorical_accuracy: 0.6111 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "batch_size = 64\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model_v64N.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model3.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history3 = model3.fit(\n",
    "    train,\n",
    "    train_target,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f09de557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m loss, accuracy, f1_score, precision, recall \u001b[38;5;241m=\u001b[39m model3\u001b[38;5;241m.\u001b[39mevaluate([np\u001b[38;5;241m.\u001b[39masarray(test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)], test_target, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#print output\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m , F1_Score:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Precision:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Recall:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy, f1_score, precision, recall))\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 2)"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history3.history['sparse_categorical_accuracy'])\n",
    "\n",
    "plt.plot(history3.history['val_sparse_categorical_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history3.history['loss'])\n",
    "\n",
    "plt.plot(history3.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#evaluate model\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall = model3.evaluate([np.asarray(test).astype('float32')], test_target, batch_size=64, verbose=0)\n",
    "\n",
    "#print output\n",
    "\n",
    "print(\"Accuracy:{} , F1_Score:{}, Precision:{}, Recall:{}\".format(accuracy, f1_score, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e90cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 12) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model3\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mbinary_accuracy], optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyswisskb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 12) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model_v32N.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model3.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history3 = model3.fit(\n",
    "    train,\n",
    "    train_target,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d70294a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1117 - sparse_categorical_accuracy: 0.6000\n",
      "Test accuracy 0.6000000238418579\n",
      "Test loss 1.1116721630096436\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.models.load_model(\"best_model_v64N.h5\")\n",
    "\n",
    "test_loss, test_acc = model4.evaluate(test, test_target)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d202e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c690d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history[\"val_\" + metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123745e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history[\"val_loss\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
